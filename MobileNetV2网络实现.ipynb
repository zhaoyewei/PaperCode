{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dense-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "torch.cuda.set_device(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "registered-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(inp,oup,stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp,oup,kernel_size=3,stride=stride,padding=1,bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self,inp,oup,stride,expand_ratio):\n",
    "        '''\n",
    "        t：扩展因子\n",
    "        c：输出特征矩阵深度\n",
    "        n：bottleneck重复次数\n",
    "        s：步距离\n",
    "        '''\n",
    "        super(InvertedResidual,self).__init__()\n",
    "        hidden_dim = inp*expand_ratio\n",
    "        self.stride = stride\n",
    "        self.use_res_connect = (self.stride==1 and inp == oup)  \n",
    "        # expannd_ratio == 1代表第一个bottlenneck不需要其一个1x1卷积，因此不用要\n",
    "        if expand_ratio == 1:\n",
    "            self.seq = nn.Sequential(\n",
    "                nn.Conv2d(hidden_dim,hidden_dim,kernel_size=3,stride=stride,\n",
    "                          padding=1,groups=hidden_dim,bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                nn.Conv2d(hidden_dim,oup,kernel_size=1,stride=1,\n",
    "                          padding=0,bias=False),\n",
    "                nn.BatchNorm2d(oup)\n",
    "            )\n",
    "        else:\n",
    "            #倒残差的情况，大部分都是这个情况\n",
    "            self.seq = nn.Sequential(\n",
    "                nn.Conv2d(inp,hidden_dim,kernel_size=1,\n",
    "                          stride=1,padding=0,bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                nn.Conv2d(hidden_dim,hidden_dim,kernel_size=3,\n",
    "                         stride=stride,padding=1,groups=hidden_dim,bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                nn.Conv2d(hidden_dim,oup,kernel_size=1,\n",
    "                         stride=1,padding=0,bias=False),\n",
    "                nn.BatchNorm2d(oup)\n",
    "            )\n",
    "        self.relu = nn.ReLU6(inplace=True)\n",
    "    def forward(self,x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.seq(x)\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "tracked-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(MobileNetV2,self).__init__()\n",
    "        block = InvertedResidual\n",
    "        inp = 32\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "        self.features = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Conv2d(3,inp,kernel_size=3,stride=2,\n",
    "                          padding=1,bias=False),\n",
    "                nn.BatchNorm2d(inp),\n",
    "                nn.ReLU6(inplace=True)\n",
    "            )])\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(320,1280,kernel_size=1,stride=1,\n",
    "                                padding=0,bias=False),\n",
    "            nn.AvgPool2d(7,stride=1),\n",
    "            nn.Conv2d(1280,num_classes,kernel_size=1,\n",
    "                    stride=1,padding=0,bias=False)\n",
    "        )\n",
    "        layers = []\n",
    "        for t,c,n,s in interverted_residual_setting:\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(inp,c,s,t))\n",
    "                else:\n",
    "                    self.features.append(block(inp,c,1,t))\n",
    "                inp = c\n",
    "        self.fc = nn.Linear(num_classes,num_classes,bias=False)\n",
    "    def forward(self,x):\n",
    "        for m in self.features:\n",
    "            x = m(x)\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "invalid-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "EPOCH = 135   #遍历数据集次数\n",
    "pre_epoch = 0  # 定义已经遍历数据集的次数\n",
    "BATCH_SIZE = 128      #批处理尺寸(batch_size)\n",
    "LR = 0.01        #学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "objective-semester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 准备数据集并预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  #先四周填充0，在吧图像随机裁剪成32*32\n",
    "    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), #R,G,B每层的归一化用到的均值和方差\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train) #训练数据集\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)   #生成一个个batch进行批训练，组成batch的时候顺序打乱取\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "# Cifar-10的标签\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "radical-measurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "[epoch:1, iter:1] Loss: 2.303 | Acc: 7.812% \n",
      "[epoch:1, iter:2] Loss: 2.305 | Acc: 8.203% \n",
      "[epoch:1, iter:3] Loss: 2.304 | Acc: 8.854% \n",
      "[epoch:1, iter:4] Loss: 2.304 | Acc: 8.789% \n",
      "[epoch:1, iter:5] Loss: 2.303 | Acc: 10.000% \n",
      "[epoch:1, iter:6] Loss: 2.301 | Acc: 9.505% \n",
      "[epoch:1, iter:7] Loss: 2.298 | Acc: 10.379% \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-74f7ee140af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print ac & loss in each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# def train_all():\n",
    "#     models = [ResNet18(),ResNet34(),ResNet50(),ResNet101(),ResNet152()]\n",
    "#     model_names = [\"R18\",\"R34\",\"R50\",\"R101\",\"R152\"]\n",
    "#     for i in range(len(models)):\n",
    "#         print(model_names[i])\n",
    "#         with open(\"ResNet.txt\",\"a\") as f:\n",
    "#             f.write(model_names[i]+\"\\n\")\n",
    "#         train(models[i])\n",
    "    \n",
    "    \n",
    "# def train(net):\n",
    "net = MobileNetV2().to(device)\n",
    "filename = 'MObileNetV2.txt'\n",
    "#define loss funtion & optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "#train\n",
    "for epoch in range(pre_epoch, EPOCH):\n",
    "    print('\\nEpoch: %d' % (epoch + 1))\n",
    "    net.train()\n",
    "    sum_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        #prepare dataset\n",
    "        length = len(trainloader)\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #forward & backward\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #print ac & loss in each batch\n",
    "        sum_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.data).cpu().sum()\n",
    "        print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% ' \n",
    "              % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "        with open(filename,\"a\") as f:\n",
    "            f.write('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% \\n' \n",
    "              % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "\n",
    "    #get the ac with testdataset in each epoch\n",
    "\n",
    "    print('Waiting Test...')\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in testloader:\n",
    "            net.eval()\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "        print('Test\\'s ac is: %.3f%%' % (100 * correct / total))\n",
    "        with open(filename,\"a\") as f:\n",
    "            f.write('Test\\'s ac is: %.3f%%\\n' % (100 * correct / total))\n",
    "\n",
    "print('Train has finished, total epoch is %d\\n' % EPOCH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-driving",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
