{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from collections import OrderedDict\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(inp,oup,kernel_size=3,stride=1,padding=1):\n",
    "    return nn.Sequential(OrderedDict([\n",
    "        (\"conv\",nn.Conv2d(inp,oup,kernel_size=kernel_size,stride=stride,padding=1,bias=False)),\n",
    "        (\"norm\",nn.BatchNorm2d(oup)),\n",
    "        (\"relu\",nn.ReLU(inplace=True))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSA_Module(nn.Module):\n",
    "    def __init__(self,inp,oup,ouc,stride=1,layer_per_block=5,use_maxpool=True):\n",
    "        '''\n",
    "        inp：当前OSA Module的输入通道\n",
    "        oup：当前OSA Module在concat之前的通道数\n",
    "        ouc：当前OSA Module在concat之后的通道数\n",
    "        stride：当前OSA Module用到的步长\n",
    "        layer_per_block：每个OSA Module有几层\n",
    "        '''\n",
    "        super(OSA_Module,self).__init__()\n",
    "#         self.maxpool = nn.ModuleList()\n",
    "#         if use_maxpool:\n",
    "#             self.maxpool.append(nn.MaxPool2d(kernel_size=3,stride=2,padding=1))\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for i in range(layer_per_block):\n",
    "            if i == 0:\n",
    "                '''\n",
    "                输入为上一个OSA Module的输出，输入通道为inp\n",
    "                '''\n",
    "                self.blocks.append(conv_bn(inp,oup))\n",
    "            else:\n",
    "                '''\n",
    "                输入为本OSA Module上一层的输出，输入通道为oup\n",
    "                '''\n",
    "                self.blocks.append(conv_bn(oup,oup))\n",
    "        '''\n",
    "        从后往前，之后相加，为inp加上layer_per_block个oup\n",
    "        '''\n",
    "        inc = inp + oup * layer_per_block\n",
    "        self.concat = nn.Sequential(\n",
    "            nn.Conv2d(inc,ouc,kernel_size=1,\n",
    "                      padding=0,bias=False),\n",
    "            nn.BatchNorm2d(ouc),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "#         for maxpool in self.maxpool:\n",
    "#             x = maxpool(x)\n",
    "        outputs = [x]\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            outputs.append(x)\n",
    "        x = torch.cat(outputs,dim=1)\n",
    "        x = self.concat(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoVNet(nn.Module):\n",
    "    def __init__(self,oups,oucs,num_layers,num_classes=10,layer_per_block=5):\n",
    "        '''\n",
    "        oups：每一个stage在concat之前的输出通道\n",
    "        oucs：每一个stage在concat之后的输出通道数\n",
    "        num_layers：每个stage有几个OSA Module\n",
    "        '''\n",
    "        super(VoVNet,self).__init__()\n",
    "        self.inp = 128\n",
    "        block = OSA_Module\n",
    "        '''\n",
    "            第一层 stem stage：\n",
    "            从3->64，64->64，最后输出128个通道，同时输出大小减半\n",
    "        '''\n",
    "        self.Stem_Stage_1 = nn.Sequential(\n",
    "                         OrderedDict([\n",
    "                             (\"stem1\",conv_bn(3,64,stride=2)),\n",
    "                             (\"stem2\",conv_bn(64,64,stride=1)),\n",
    "                             (\"stem3\",conv_bn(64,128,stride=1))\n",
    "                         ]))\n",
    "        '''\n",
    "        stage 2:表示输入是上一个stage的输出，故输入为self.inp\n",
    "        '''\n",
    "        self.OSA_Stage_2 = self.make_layers(block,self.inp,oups[0],oucs[0],num_layers[0],2,False)\n",
    "        '''\n",
    "        否则就是本层stage的上一个OSA Module的输出\n",
    "        '''\n",
    "        self.OSA_Stage_3 = self.make_layers(block,oucs[0],oups[1],oucs[1],num_layers[1],3,True)\n",
    "        self.OSA_Stage_4 = self.make_layers(block,oucs[1],oups[2],oucs[2],num_layers[2],4,True)\n",
    "        self.OSA_Stage_5 = self.make_layers(block,oucs[2],oups[3],oucs[3],num_layers[3],5,True)\n",
    "        \n",
    "#         '''\n",
    "#         对每个stage建立对应数目的OSA Module\n",
    "#         '''\n",
    "#         for i in range(len(num_layers)):\n",
    "#             if i == 0:\n",
    "#                 '''\n",
    "#                 i==\n",
    "#                 '''\n",
    "#                 self.layers.append(self.make_layers(block,self.inp,oups[i],oucs[i],num_layers[i],i+2))\n",
    "#                 self.inp = oucs[-1]\n",
    "#             else:\n",
    "#                 '''\n",
    "#                 否则就是本层stage的上一个OSA Module的输出\n",
    "#                 '''\n",
    "#                 self.layers.append(self.make_layers(block,oups[i-1],oups[i],oucs[i],num_layers[i],i+2))\n",
    "            \n",
    "        self.fc = nn.Linear(oucs[3],num_classes)\n",
    "    def make_layers(self,block,inp,oup,ouc,num_layers,dep,use_maxpool=True,layers_per_block=5):\n",
    "        '''\n",
    "        block：模块，这里是OSA\n",
    "        inp：当前OSA Module的输入通道数\n",
    "        oup：当前OSA Module在concat之前的通道数\n",
    "        ouc：当前OSA Module在concat之后的通道数\n",
    "        num_layers：本层有多少个OSA Module\n",
    "        dep：第几个stage，用来写名字用\n",
    "        '''\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(block(inp,oup,ouc,use_maxpool=use_maxpool))\n",
    "            inp = ouc\n",
    "        layers.append(nn.MaxPool2d(kernel_size=3,stride=2,padding=1))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.Stem_Stage_1(x)\n",
    "        x = self.OSA_Stage_2(x)\n",
    "        x = self.OSA_Stage_3(x)\n",
    "        x = self.OSA_Stage_4(x)\n",
    "        x = self.OSA_Stage_5(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VoVNet27():\n",
    "    return VoVNet([64,80,96,112],[128,256,384,512],[1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VoVNet39():\n",
    "    return VoVNet([128,160,192,224],[256,512,768,1024],[1,1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VoVNet57():\n",
    "    return VoVNet([128,160,192,224],[256,512,768,1024],[1,1,4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "EPOCH = 100   #遍历数据集次数\n",
    "pre_epoch = 0  # 定义已经遍历数据集的次数\n",
    "BATCH_SIZE = 64      #批处理尺寸(batch_size)\n",
    "LR = 0.01        #学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据集并预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),  #先四周填充0，在吧图像随机裁剪成32*32\n",
    "    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), #R,G,B每层的归一化用到的均值和方差\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),  #先四周填充0，在吧图像随机裁剪成32*32\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train) #训练数据集\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)   #生成一个个batch进行批训练，组成batch的时候顺序打乱取\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "# Cifar-10的标签\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'VoVNet.txt'\n",
    "def train_all():\n",
    "    models = [VoVNet57()]\n",
    "    model_names = [\"V27\",\"V39\",\"V57\"]\n",
    "    for i in range(len(models)):\n",
    "        print(model_names[i])\n",
    "        with open(filename,\"a\") as f:\n",
    "            f.write(model_names[i]+\"\\n\")\n",
    "        train(models[i])\n",
    "    \n",
    "    \n",
    "def train(net):\n",
    "    net = net.to(device)\n",
    "    #define loss funtion & optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "    #train\n",
    "    for epoch in range(pre_epoch, EPOCH):\n",
    "        print('\\nEpoch: %d' % (epoch + 1))\n",
    "        net.train()\n",
    "        sum_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            #prepare dataset\n",
    "            length = len(trainloader)\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward & backward\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #print ac & loss in each batch\n",
    "            sum_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.data).cpu().sum()\n",
    "            print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% ' \n",
    "                  % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "            with open(filename,\"a\") as f:\n",
    "                f.write('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% \\n' \n",
    "                  % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "\n",
    "        #get the ac with testdataset in each epoch\n",
    "\n",
    "        print('Waiting Test...')\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in testloader:\n",
    "                net.eval()\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            print('Test\\'s ac is: %.3f%%' % (100 * correct / total))\n",
    "            with open(filename,\"a\") as f:\n",
    "                f.write('Test\\'s ac is: %.3f%%\\n' % (100 * correct / total))\n",
    "\n",
    "    print('Train has finished, total epoch is %d\\n' % EPOCH)\n",
    "    \n",
    "# train_all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
