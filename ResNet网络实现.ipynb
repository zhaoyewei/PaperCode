{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "universal-visit",
   "metadata": {},
   "source": [
    "# 实现Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "naughty-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "torch.cuda.set_device(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "engaging-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,inchannel,outchannel,stride=1):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(inchannel,outchannel,kernel_size=3,\n",
    "                      stride=stride,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel,outchannel,kernel_size=3,\n",
    "                     stride=1,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.shortcut =  nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel,outchannel,kernel_size=1,\n",
    "                         stride=stride,bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        out = self.seq(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "weighted-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,inchannel,outchannel,stride=1):\n",
    "        super(ResBlock,self).__init__()\n",
    "        planes = 4\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(inchannel,outchannel,kernel_size=1,stride=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel,outchannel,kernel_size=3,\n",
    "                      stride=stride,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel,outchannel*planes,kernel_size=1,stride=1,\n",
    "                     bias=False),\n",
    "            nn.BatchNorm2d(outchannel*planes),\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if inchannel != outchannel * planes or stride != 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel,outchannel*planes,kernel_size=1,\n",
    "                               stride=stride,bias=False),\n",
    "                nn.BatchNorm2d(outchannel*planes)\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        out = self.seq(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coated-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResNet18(nn.Module):\n",
    "#     def __init__(self,block,num_classes=10):\n",
    "#         super(ResNet18,self).__init__()\n",
    "#         self.inchannel = 64\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "#         )\n",
    "#         self.layer1 = self.make_layers(block,64,2,stride=1)\n",
    "#         self.layer2 = self.make_layers(block,128,2,stride=2)\n",
    "#         self.layer3 = self.make_layers(block,256,2,stride=2)\n",
    "#         self.layer4 = self.make_layers(block,512,2,stride=2)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "#         self.fc = nn.Linear(512,num_classes)\n",
    "#     def make_layers(self,block,outchannel,num_blocks,stride):\n",
    "#         strides = [stride] + [1] * (num_blocks - 1)\n",
    "#         layers = []\n",
    "#         for stride in strides:\n",
    "#             layers.append(block(self.inchannel,outchannel,stride))\n",
    "#             self.inchannel = outchannel\n",
    "#         return nn.Sequential(*layers)\n",
    "#     def forward(self,x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(x,1)\n",
    "#         x = self.fc(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "divine-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResNet34(nn.Module):\n",
    "#     def __init__(self,block,num_classes=10):\n",
    "#         super(ResNet34,self).__init__()\n",
    "#         self.inchannel = 64\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "#         )\n",
    "#         self.layer1 = self.make_layers(block,64,3,stride=1)\n",
    "#         self.layer2 = self.make_layers(block,128,4,stride=2)\n",
    "#         self.layer3 = self.make_layers(block,256,6,stride=2)\n",
    "#         self.layer4 = self.make_layers(block,512,3,stride=2)\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "#         self.fc = nn.Linear(512,num_classes)\n",
    "#     def make_layers(self,block,outchannel,num_blocks,stride):\n",
    "#         strides = [stride] + [1] * (num_blocks - 1)\n",
    "#         layers = []\n",
    "#         for stride in strides:\n",
    "#             layers.append(block(self.inchannel,outchannel,stride))\n",
    "#             self.inchannel = outchannel\n",
    "#         return nn.Sequential(*layers)\n",
    "#     def forward(self,x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(x,1)\n",
    "#         x = self.fc(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sudden-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResNet50(nn.Module):\n",
    "#     def __init__(self,block,num_classes=100):\n",
    "#         super(ResNet50,self).__init__()\n",
    "#         self.inchannel = 64\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(3,self.inchannel,7,stride=2,padding=3,bias=False),\n",
    "#             nn.BatchNorm2d(self.inchannel),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "#         )\n",
    "#         self.layer1 = self.make_layers(block, 64,3,stride=1)\n",
    "#         self.layer2 = self.make_layers(block,128,4,stride=2)\n",
    "#         self.layer3 = self.make_layers(block,256,6,stride=2)\n",
    "#         self.layer4 = self.make_layers(block,512,3,stride=2)\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "#         self.fc = nn.Linear(512 * 4,num_classes)\n",
    "#     def make_layers(self,block,outchannel,num_blocks,stride=1):\n",
    "#         strides = [stride] + [1] * (num_blocks - 1)\n",
    "#         layers = []\n",
    "#         for stride in strides:\n",
    "#             layers.append(block(self.inchannel,outchannel,stride=stride))\n",
    "#             self.inchannel = outchannel * 4\n",
    "        \n",
    "#         return nn.Sequential(*layers)\n",
    "#     def forward(self,x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(x,start_dim=1)\n",
    "#         x = self.fc(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unable-marketplace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# net = ResNet50(ResBlock).to(device)\n",
    "\n",
    "# #define loss funtion & optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "# #train\n",
    "# for epoch in range(pre_epoch, EPOCH):\n",
    "#     print('\\nEpoch: %d' % (epoch + 1))\n",
    "#     net.train()\n",
    "#     sum_loss = 0.0\n",
    "#     correct = 0.0\n",
    "#     total = 0.0\n",
    "#     for i, data in enumerate(trainloader, 0):\n",
    "#         #prepare dataset\n",
    "#         length = len(trainloader)\n",
    "#         inputs, labels = data\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         #forward & backward\n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         #print ac & loss in each batch\n",
    "#         sum_loss += loss.item()\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += predicted.eq(labels.data).cpu().sum()\n",
    "#         print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% ' \n",
    "#               % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "        \n",
    "#     #get the ac with testdataset in each epoch\n",
    "#     print('Waiting Test...')\n",
    "#     with torch.no_grad():\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "#         for data in testloader:\n",
    "#             net.eval()\n",
    "#             images, labels = data\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             outputs = net(images)\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum()\n",
    "#         print('Test\\'s ac is: %.3f%%' % (100 * correct / total))\n",
    "\n",
    "# print('Train has finished, total epoch is %d' % EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "needed-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResNet101(nn.Module):\n",
    "#     def __init__(self,block,num_classes=100):\n",
    "#         super(ResNet101,self).__init__()\n",
    "#         self.inchannel = 64\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(3,self.inchannel,7,stride=2,padding=3,bias=False),\n",
    "#             nn.BatchNorm2d(self.inchannel),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "#         )\n",
    "#         self.layer1 = self.make_layers(block, 64,3,stride=1)\n",
    "#         self.layer2 = self.make_layers(block,128,4,stride=2)\n",
    "#         self.layer3 = self.make_layers(block,256,23,stride=2)\n",
    "#         self.layer4 = self.make_layers(block,512,3,stride=2)\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "#         self.fc = nn.Linear(512 * 4,num_classes)\n",
    "#     def make_layers(self,block,outchannel,num_blocks,stride=1):\n",
    "#         strides = [stride] + [1] * (num_blocks - 1)\n",
    "#         layers = []\n",
    "#         for stride in strides:\n",
    "#             layers.append(block(self.inchannel,outchannel,stride=stride))\n",
    "#             self.inchannel = outchannel * 4\n",
    "        \n",
    "#         return nn.Sequential(*layers)\n",
    "#     def forward(self,x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.layer4(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(x,start_dim=1)\n",
    "#         x = self.fc(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unable-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,block,num_layers,plane=4,num_classes=100):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.plane = plane\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3,self.inchannel,7,stride=2,padding=3,bias=False),\n",
    "            nn.BatchNorm2d(self.inchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        )\n",
    "        self.layer1 = self.make_layers(block, 64,num_layers[0],stride=1)\n",
    "        self.layer2 = self.make_layers(block,128,num_layers[1],stride=2)\n",
    "        self.layer3 = self.make_layers(block,256,num_layers[2],stride=2)\n",
    "        self.layer4 = self.make_layers(block,512,num_layers[3],stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512 * self.plane,num_classes)\n",
    "    def make_layers(self,block,outchannel,num_blocks,stride=1):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel,outchannel,stride=stride))\n",
    "            self.inchannel = outchannel * self.plane\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fantastic-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(BasicBlock,[2,2,2,2],plane=1)\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock,[3,4,6,3],plane=1)\n",
    "def ResNet50():\n",
    "    return ResNet(ResBlock,[3,4,6,3],plane=4)\n",
    "def ResNet101():\n",
    "    return ResNet(ResBlock,[3,4,23,3],plane=4)\n",
    "def ResNet152():\n",
    "    return ResNet(ResBlock,[3,8,36,3],plane=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lesser-saying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 超参数设置\n",
    "EPOCH = 135   #遍历数据集次数\n",
    "pre_epoch = 0  # 定义已经遍历数据集的次数\n",
    "BATCH_SIZE = 1024      #批处理尺寸(batch_size)\n",
    "LR = 0.01        #学习率\n",
    "\n",
    "# 准备数据集并预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  #先四周填充0，在吧图像随机裁剪成32*32\n",
    "    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), #R,G,B每层的归一化用到的均值和方差\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train) #训练数据集\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)   #生成一个个batch进行批训练，组成batch的时候顺序打乱取\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "# Cifar-10的标签\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dried-secretary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_all():\n",
    "    models = [ResNet18(),ResNet34(),ResNet50(),ResNet101(),ResNet152()]\n",
    "    model_names = [\"R18\",\"R34\",\"R50\",\"R101\",\"R152\"]\n",
    "    for i in range(len(models)):\n",
    "        print(model_names[i])\n",
    "        with open(\"ResNet.txt\",\"a\") as f:\n",
    "            f.write(model_names[i]+\"\\n\")\n",
    "        train(models[i])\n",
    "    \n",
    "    \n",
    "def train(net):\n",
    "    net = net.to(device)\n",
    "\n",
    "    #define loss funtion & optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=1e-3)\n",
    "    #train\n",
    "    for epoch in range(pre_epoch, EPOCH):\n",
    "        print('\\nEpoch: %d' % (epoch + 1))\n",
    "        net.train()\n",
    "        sum_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            #prepare dataset\n",
    "            length = len(trainloader)\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward & backward\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #print ac & loss in each batch\n",
    "            sum_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.data).cpu().sum()\n",
    "            print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% ' \n",
    "                  % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "            with open(\"ResNet.txt\",\"a\") as f:\n",
    "                f.write('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% \\n' \n",
    "                  % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "\n",
    "        #get the ac with testdataset in each epoch\n",
    "        \n",
    "        print('Waiting Test...')\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in testloader:\n",
    "                net.eval()\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            print('Test\\'s ac is: %.3f%%' % (100 * correct / total))\n",
    "            with open(\"ResNet.txt\",\"a\") as f:\n",
    "                f.write('Test\\'s ac is: %.3f%%\\n' % (100 * correct / total))\n",
    "\n",
    "    print('Train has finished, total epoch is %d\\n' % EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "noted-exclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R18\n",
      "\n",
      "Epoch: 1\n",
      "[epoch:1, iter:1] Loss: 4.899 | Acc: 0.879% \n",
      "[epoch:1, iter:2] Loss: 4.591 | Acc: 3.223% \n",
      "[epoch:1, iter:3] Loss: 4.173 | Acc: 7.747% \n",
      "[epoch:1, iter:4] Loss: 3.807 | Acc: 10.767% \n",
      "[epoch:1, iter:5] Loss: 3.491 | Acc: 13.711% \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0a3ba0553fdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-aebad50218c6>\u001b[0m in \u001b[0;36mtrain_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ResNet.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-aebad50218c6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m#print ac & loss in each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
